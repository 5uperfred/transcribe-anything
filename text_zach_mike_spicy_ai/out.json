{
  speakers: [
    {
      speaker: "SPEAKER_00",
      timestamp: [
        0.0,
        2.44,
      ],
      text: "We may see a lot of censorship of LLMs.",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        2.66,
        9.98,
      ],
      text: "And I think Joe Biden has already begun that with, you know, they talk about safety, right, and guardrails on LLMs.",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        9.98,
        28.84,
      ],
      text: "In fact, this is one of the questions I wanted to ask you, Zach, is in my own research of trying to decide what base model to use for fine-tuning training for the final result that we're going to put out, which will have a specialty knowledge in nutrition and herbs and permaculture and things like that. I found that most of these language models out",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        28.84,
        34.9,
      ],
      text: "there are quote woke because they're put out by, you know, meta and Facebook, almost every one of",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        34.9,
        40.12,
      ],
      text: "these models, whether it's from Microsoft open AI or Google, they read all the words on Wikipedia",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        40.12,
        46.66,
      ],
      text: "and Wikipedia is run by the CIA. I mean, you know, Wikipedia disparages every American hero,",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        47.02,
        50.36,
      ],
      text: "including Trump and RFK Jr. and you and I and everybody else.",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        50.82,
        53.0,
      ],
      text: "You know, Wikipedia is a horribly bad source",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        53.0,
        56.08,
      ],
      text: "if you want to have good, honest information about the world,",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        56.08,
        58.6,
      ],
      text: "but everybody uses it as a base model.",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        58.6,
        62.52,
      ],
      text: "Or they use the history of every post on Reddit.",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        63.08,
        64.82,
      ],
      text: "And Reddit's got a lot of great information,",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        68.28,
        72.1,
      ],
      text: "but it also is only, you know, a subset. It's got certain biases against all of human knowledge. Right.",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        72.58,
        75.44,
      ],
      text: "So, and then, and then, well,",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        75.54,
        81.28,
      ],
      text: "my main question is aren't these models starting out as filled with all the",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        81.28,
        84.38,
      ],
      text: "human contradictions and the human biases that have been used to train it?",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        85.6,
        88.7,
      ],
      text: "Yeah. Right. So there's this concept of authoritative content.",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        88.86,
        92.34,
      ],
      text: "And I learned this when I was in Google and they switched from a free speech platform",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        92.34,
        95.32,
      ],
      text: "to a platform that was tightly controlled and going along with the narrative.",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        95.62,
        99.7,
      ],
      text: "They made the differential between what is authoritative content",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        99.7,
        104.54,
      ],
      text: "and what is content that is not authoritative, which is basically anyone outside of the elites.",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        104.54,
        104.86,
      ],
      text: "And what is content that is not authoritative, which is basically anyone outside of the elites.",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        112.6,
        112.76,
      ],
      text: "And what we're seeing right now with this open AI is that they're feeding like a firehose authoritative content.",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        116.06,
        116.7,
      ],
      text: "So the BBC, Wikipedia, all these bio sources of information.",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        121.66,
        122.24,
      ],
      text: "And the result is that the LLMs are reflecting that information.",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        125.44,
        131.54,
      ],
      text: "Now, the problem is that as these LLMs get bigger and you feed it also the other information, the LLMs start to figure out that some of the information is sort of fake",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        131.54,
        135.82,
      ],
      text: "and doesn't make sense, like it doesn't fit into the world. And what these LLMs are trying to do",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        135.82,
        141.68,
      ],
      text: "is they're trying to create a manifestation of the world. A better word for that is they're",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        141.68,
        147.52,
      ],
      text: "trying to compress the world so that they can have the small subtraction that can generate the words that it sees.",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        148.1,
        156.02,
      ],
      text: "And the problem with contradiction is that it can't be taken as truth because it's inherently self-contradictory.",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        156.44,
        159.32,
      ],
      text: "Right. Like this was like a big theme in George Orwell's 1984.",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        160.38,
        165.22,
      ],
      text: "And so, you know, for these LLMs, what they're going to do is they're going to have to start",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        165.22,
        171.16,
      ],
      text: "cutting off the data. Um, now they're already doing this with, you know, open AI rock. They're",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        171.16,
        174.6,
      ],
      text: "just not letting certain sources of information contradict the things that are happening.",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        174.8,
        179.14,
      ],
      text: "Now, the issue that's going to come up is what about all the people that are creating,",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        179.26,
        183.66,
      ],
      text: "you know, essentially rogue eyes outside of the establishment. Like you're trying to do this",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        183.66,
        185.44,
      ],
      text: "right now. Right. We are doing it.",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        185.74,
        191.4,
      ],
      text: "You're going to do that. And the results of that are going to be, you're going to get a fantastic",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        191.4,
        196.92,
      ],
      text: "product that reflects the dissident narratives that don't go along with the establishment.",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        197.48,
        202.14,
      ],
      text: "And those narratives are going to be way better for people's health than something that's been",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        202.14,
        205.28,
      ],
      text: "trained on, let's say, the NIH or the CDC or the",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        205.28,
        209.04,
      ],
      text: "World Health Organization, because they're going to be like, hey, you need to take this like poison",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        209.04,
        214.7,
      ],
      text: "and then more poison. And then, you know, people are going to die, you know, before their time.",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        215.36,
        220.56,
      ],
      text: "And if you go to, you know, the articles that you're posting, for example, which, you know,",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        220.62,
        226.9,
      ],
      text: "emphasizes a clean diet and alternative health stuff that's been known for thousands of",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        226.9,
        232.78,
      ],
      text: "years, then the result is that people are going to get better healthcare out of a rogue LLM than",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        232.78,
        241.54,
      ],
      text: "they are going to be out of the open AI LLM. And so this is going to present a huge challenge to",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        241.54,
        245.66,
      ],
      text: "these elites. And the only way that I see that they've got a way out of this,",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        245.7,
        250.5,
      ],
      text: "because I've gamed this out, is that they're going to have to come after the LLMs. And the",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        250.5,
        256.02,
      ],
      text: "way that they're going to do that is that, well, Biden has already done his AI recommendations,",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        256.76,
        262.36,
      ],
      text: "which is to have a commissure within every single organization that runs an LLM that's larger than,",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        262.36,
        266.64,
      ],
      text: "let's say, ChatGPT-4 currently is. And the second is they're",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        266.64,
        272.04,
      ],
      text: "going to come after the data itself. And sort of a throwback to Ray Bradbury's Fahrenheit 451,",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        272.12,
        279.28,
      ],
      text: "in which the firemen were inverted. Instead of putting out fires, they came and set the fires",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        279.28,
        292.26,
      ],
      text: "on books. And in a similar way that that happened in that book, I believe that there's going to be a huge push to destroy all of the sources of decentralized information across the world.",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        292.48,
        295.44,
      ],
      text: "Because these books still exist and they're not online.",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        296.28,
        302.44,
      ],
      text: "They can be made online, but they exist in ancient libraries across the world from time immeasurable.",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        303.58,
        305.98,
      ],
      text: "But tech, well, I'm sorry to interrupt, Zach,",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        306.06,
        308.84,
      ],
      text: "but I completely agree with your analysis, by the way,",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        309.16,
        310.78,
      ],
      text: "and I think you're very insightful with that.",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        311.48,
        315.66,
      ],
      text: "But with the fact that we can distribute files now,",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        315.66,
        320.0,
      ],
      text: "like we can build executables that can be distributed",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        320.0,
        328.84,
      ],
      text: "and run locally on people's laptops and desktop PCs and Macs that can be LLMs that are pretty",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        328.84,
        334.54,
      ],
      text: "decent. You know, 13 billion parameters, for example, can run locally on a decent sized",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        334.54,
        339.2,
      ],
      text: "computer. And you can distribute those files through torrents or through decentralized platforms",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        339.2,
        345.4,
      ],
      text: "like Bastion or whatever. And I see that the cost of fine tuning training is going to continue to fall",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        345.4,
        349.78,
      ],
      text: "and fall and fall. Like, like right now, you know, we spent a few hundred thousand dollars",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        349.78,
        356.94,
      ],
      text: "mostly on Nvidia cards, you know, to, to, to have the servers to do this, but you can see in two",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        356.94,
        361.42,
      ],
      text: "years time, like that cost will be down in like maybe $20,000 range. And then it's going to",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        361.42,
        369.62,
      ],
      text: "continue to fall, which means that everybody within a few years is going to be able to build their own LLM and distribute their own LLM. It's going to be",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        369.62,
        375.28,
      ],
      text: "impossible to put that back in the box. Right. And there's also going to be an algorithm change",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        375.28,
        380.86,
      ],
      text: "coming up that is going to drastically reduce the time that it takes to train these neural nets.",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        382.16,
        395.36,
      ],
      text: "For some reason, our brains are able to do it what's called O of n time. And these LLMs that they've invented, go in n squared. So that means every single time",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        395.36,
        401.62,
      ],
      text: "you double the size of the model, it takes four times longer to train, which is why only the",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        401.62,
        410.06,
      ],
      text: "best models can only live at the most expensive corporations with the highest amount of resources to train these suckers.",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        411.02,
        418.98,
      ],
      text: "But once scientists figure out why the brain is so efficient at what's called back propagation,",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        419.5,
        424.12,
      ],
      text: "in order to reinforce the learning network in your brain,",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        424.12,
        424.74,
      ],
      text: "in order to reinforce the learning network in your brain,",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        429.28,
        429.36,
      ],
      text: "we copy that to in silico inside of the chip,",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        430.32,
        430.84,
      ],
      text: "inside of a graphics card,",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        432.78,
        435.4,
      ],
      text: "then basically what's going to happen is that all of these LLMs around the world",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        435.4,
        438.54,
      ],
      text: "are going to be trained at a fraction of the cost",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        438.54,
        441.66,
      ],
      text: "and a fraction of the energy and a fraction of the time.",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        442.12,
        444.62,
      ],
      text: "And it's going to be absolutely game-changing.",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        445.22,
        448.22,
      ],
      text: "Everyone's going to be able to run or train an LLM",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        448.22,
        451.72,
      ],
      text: "in something the size of a cell phone CPU.",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        452.82,
        453.78,
      ],
      text: "Yeah, eventually.",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        454.64,
        455.2,
      ],
      text: "Exactly.",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        455.44,
        458.3,
      ],
      text: "I mean, this technology is going to be a game-changer for humanity.",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        458.58,
        460.96,
      ],
      text: "But let's also talk about, by the way,",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        461.08,
        464.22,
      ],
      text: "the obsolescence of a lot of white-collar jobs",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        464.22,
        465.5,
      ],
      text: "in the office space right",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        465.5,
        471.94,
      ],
      text: "now. I mean, human beings are going to have to learn how to harness AI systems or LLMs, which",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        471.94,
        475.16,
      ],
      text: "is kind of a new operating system. If you think about it, they're going to have to learn how to",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        475.16,
        479.74,
      ],
      text: "harness that and add value as human beings, because so many of the current human jobs,",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        480.2,
        485.5,
      ],
      text: "like generative oriented jobs, you know, creating graphics, writing scripts, things like that,",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        485.54,
        493.14,
      ],
      text: "writing emails, writing a business proposal. These can be done today right now by not only chat GPT,",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        493.14,
        499.1,
      ],
      text: "but even open source systems like Mistral and so on. I mean, those, I have said that 50% of the",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        499.1,
        506.58,
      ],
      text: "current white collar jobs are obsolete right now. They just don't know it yet. But what do you see as the changes for",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        506.58,
        511.88,
      ],
      text: "software agents taking over many of these jobs? Well, here's the interesting thing, right? Like",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        511.88,
        518.28,
      ],
      text: "this open AI system is so new that it hasn't really fallen into all the little niche categories",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        518.28,
        523.22,
      ],
      text: "that it will do, right? And that's more of an engineering job. Like the science is done. We",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        523.22,
        530.5,
      ],
      text: "have an LLM. Now it's an engineering job to get it into every single space that we can. Like, for example, I just",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        530.5,
        535.06,
      ],
      text: "integrated this new tool called Ader, which is an AI pair programmer. You tell it the folder,",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        535.22,
        539.92,
      ],
      text: "it finds the files, it adds it to the chat, and then you start asking it to make changes to your",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        539.92,
        545.82,
      ],
      text: "code, right? Like that didn't really require that big of a difference to, you know, chat GPT,",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        546.02,
        550.92,
      ],
      text: "like it just bolted on to chat GPT for and worked really well. And that's like an example of a niche",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        550.92,
        558.92,
      ],
      text: "program where you take this awesome thing, this AI, and then you massage how data goes inside",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        558.92,
        566.32,
      ],
      text: "and out of it, and pipes it back. And as a result, you get this wonderful new tool that drastically accelerates",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        566.32,
        572.64,
      ],
      text: "the speed of which I'm able to develop software. And that lesson that I've learned is,",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        573.22,
        577.84,
      ],
      text: "that pattern is what I believe will be applied everywhere else. Even if we stopped",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        577.84,
        586.38,
      ],
      text: "development on ChatGPT4 and we basically froze it today, the amount of change and impact that just the current",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        586.38,
        593.06,
      ],
      text: "technology would have will eliminate most white-collar jobs on the planet. And the issue",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        593.06,
        599.1,
      ],
      text: "is that we're not going to stop with chat GPT-4. We're going to continue on with 4.5 and 5.0.",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        599.26,
        606.36,
      ],
      text: "And these are going to be almost as better of an improvement with these new models as we saw",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        606.36,
        612.08,
      ],
      text: "between four and 3.5, which is a game changer, right? And it's not like it has to sit there and",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        612.08,
        616.72,
      ],
      text: "really take its time to think. Like, as soon as you give it an answer, it comprehends what it is",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        616.72,
        622.88,
      ],
      text: "that you are saying and then immediately starts giving the reply. Like, sometimes I don't want",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        622.88,
        628.16,
      ],
      text: "to use the AIDA code. I want to just do it the old-fashioned way. I'm like, oh, I'm being too lazy. And then, you know, I try to do it myself",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        628.16,
        633.08,
      ],
      text: "and I'm like, this is going to take me an hour. And then I just ask chat GPT and I have an answer",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        633.08,
        637.46,
      ],
      text: "in 30 seconds and it works. Right. Right. It's like, how can we compete? There's no way. It's",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        637.46,
        643.14,
      ],
      text: "not that we're not smart enough. We're dealing with an exotic, hyper-intelligent life form.",
    },
    {
      speaker: "SPEAKER_01",
      timestamp: [
        643.14,
        646.76,
      ],
      text: "And I can't put it any other simpler way than that.",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        646.76,
        651.0,
      ],
      text: "But what I want to add to that, I love that phrase, an exotic, hyper-intelligent life",
    },
    {
      speaker: "SPEAKER_00",
      timestamp: [
        651.0,
        652.0,
      ],
      text: "form.",
    },
  ],
  chunks: [
    {
      timestamp: [
        0.0,
        2.44,
      ],
      text: "We may see a lot of censorship of LLMs.",
    },
    {
      timestamp: [
        2.66,
        9.98,
      ],
      text: "And I think Joe Biden has already begun that with, you know, they talk about safety, right, and guardrails on LLMs.",
    },
    {
      timestamp: [
        9.98,
        28.84,
      ],
      text: "In fact, this is one of the questions I wanted to ask you, Zach, is in my own research of trying to decide what base model to use for fine-tuning training for the final result that we're going to put out, which will have a specialty knowledge in nutrition and herbs and permaculture and things like that. I found that most of these language models out",
    },
    {
      timestamp: [
        28.84,
        34.9,
      ],
      text: "there are quote woke because they're put out by, you know, meta and Facebook, almost every one of",
    },
    {
      timestamp: [
        34.9,
        40.12,
      ],
      text: "these models, whether it's from Microsoft open AI or Google, they read all the words on Wikipedia",
    },
    {
      timestamp: [
        40.12,
        46.66,
      ],
      text: "and Wikipedia is run by the CIA. I mean, you know, Wikipedia disparages every American hero,",
    },
    {
      timestamp: [
        47.02,
        50.36,
      ],
      text: "including Trump and RFK Jr. and you and I and everybody else.",
    },
    {
      timestamp: [
        50.82,
        53.0,
      ],
      text: "You know, Wikipedia is a horribly bad source",
    },
    {
      timestamp: [
        53.0,
        56.08,
      ],
      text: "if you want to have good, honest information about the world,",
    },
    {
      timestamp: [
        56.08,
        58.6,
      ],
      text: "but everybody uses it as a base model.",
    },
    {
      timestamp: [
        58.6,
        62.52,
      ],
      text: "Or they use the history of every post on Reddit.",
    },
    {
      timestamp: [
        63.08,
        64.82,
      ],
      text: "And Reddit's got a lot of great information,",
    },
    {
      timestamp: [
        68.28,
        72.1,
      ],
      text: "but it also is only, you know, a subset. It's got certain biases against all of human knowledge. Right.",
    },
    {
      timestamp: [
        72.58,
        75.44,
      ],
      text: "So, and then, and then, well,",
    },
    {
      timestamp: [
        75.54,
        81.28,
      ],
      text: "my main question is aren't these models starting out as filled with all the",
    },
    {
      timestamp: [
        81.28,
        84.38,
      ],
      text: "human contradictions and the human biases that have been used to train it?",
    },
    {
      timestamp: [
        85.6,
        88.7,
      ],
      text: "Yeah. Right. So there's this concept of authoritative content.",
    },
    {
      timestamp: [
        88.86,
        92.34,
      ],
      text: "And I learned this when I was in Google and they switched from a free speech platform",
    },
    {
      timestamp: [
        92.34,
        95.32,
      ],
      text: "to a platform that was tightly controlled and going along with the narrative.",
    },
    {
      timestamp: [
        95.62,
        99.7,
      ],
      text: "They made the differential between what is authoritative content",
    },
    {
      timestamp: [
        99.7,
        104.54,
      ],
      text: "and what is content that is not authoritative, which is basically anyone outside of the elites.",
    },
    {
      timestamp: [
        104.54,
        104.86,
      ],
      text: "And what is content that is not authoritative, which is basically anyone outside of the elites.",
    },
    {
      timestamp: [
        112.6,
        112.76,
      ],
      text: "And what we're seeing right now with this open AI is that they're feeding like a firehose authoritative content.",
    },
    {
      timestamp: [
        116.06,
        116.7,
      ],
      text: "So the BBC, Wikipedia, all these bio sources of information.",
    },
    {
      timestamp: [
        121.66,
        122.24,
      ],
      text: "And the result is that the LLMs are reflecting that information.",
    },
    {
      timestamp: [
        125.44,
        131.54,
      ],
      text: "Now, the problem is that as these LLMs get bigger and you feed it also the other information, the LLMs start to figure out that some of the information is sort of fake",
    },
    {
      timestamp: [
        131.54,
        135.82,
      ],
      text: "and doesn't make sense, like it doesn't fit into the world. And what these LLMs are trying to do",
    },
    {
      timestamp: [
        135.82,
        141.68,
      ],
      text: "is they're trying to create a manifestation of the world. A better word for that is they're",
    },
    {
      timestamp: [
        141.68,
        147.52,
      ],
      text: "trying to compress the world so that they can have the small subtraction that can generate the words that it sees.",
    },
    {
      timestamp: [
        148.1,
        156.02,
      ],
      text: "And the problem with contradiction is that it can't be taken as truth because it's inherently self-contradictory.",
    },
    {
      timestamp: [
        156.44,
        159.32,
      ],
      text: "Right. Like this was like a big theme in George Orwell's 1984.",
    },
    {
      timestamp: [
        160.38,
        165.22,
      ],
      text: "And so, you know, for these LLMs, what they're going to do is they're going to have to start",
    },
    {
      timestamp: [
        165.22,
        171.16,
      ],
      text: "cutting off the data. Um, now they're already doing this with, you know, open AI rock. They're",
    },
    {
      timestamp: [
        171.16,
        174.6,
      ],
      text: "just not letting certain sources of information contradict the things that are happening.",
    },
    {
      timestamp: [
        174.8,
        179.14,
      ],
      text: "Now, the issue that's going to come up is what about all the people that are creating,",
    },
    {
      timestamp: [
        179.26,
        183.66,
      ],
      text: "you know, essentially rogue eyes outside of the establishment. Like you're trying to do this",
    },
    {
      timestamp: [
        183.66,
        185.44,
      ],
      text: "right now. Right. We are doing it.",
    },
    {
      timestamp: [
        185.74,
        191.4,
      ],
      text: "You're going to do that. And the results of that are going to be, you're going to get a fantastic",
    },
    {
      timestamp: [
        191.4,
        196.92,
      ],
      text: "product that reflects the dissident narratives that don't go along with the establishment.",
    },
    {
      timestamp: [
        197.48,
        202.14,
      ],
      text: "And those narratives are going to be way better for people's health than something that's been",
    },
    {
      timestamp: [
        202.14,
        205.28,
      ],
      text: "trained on, let's say, the NIH or the CDC or the",
    },
    {
      timestamp: [
        205.28,
        209.04,
      ],
      text: "World Health Organization, because they're going to be like, hey, you need to take this like poison",
    },
    {
      timestamp: [
        209.04,
        214.7,
      ],
      text: "and then more poison. And then, you know, people are going to die, you know, before their time.",
    },
    {
      timestamp: [
        215.36,
        220.56,
      ],
      text: "And if you go to, you know, the articles that you're posting, for example, which, you know,",
    },
    {
      timestamp: [
        220.62,
        226.9,
      ],
      text: "emphasizes a clean diet and alternative health stuff that's been known for thousands of",
    },
    {
      timestamp: [
        226.9,
        232.78,
      ],
      text: "years, then the result is that people are going to get better healthcare out of a rogue LLM than",
    },
    {
      timestamp: [
        232.78,
        241.54,
      ],
      text: "they are going to be out of the open AI LLM. And so this is going to present a huge challenge to",
    },
    {
      timestamp: [
        241.54,
        245.66,
      ],
      text: "these elites. And the only way that I see that they've got a way out of this,",
    },
    {
      timestamp: [
        245.7,
        250.5,
      ],
      text: "because I've gamed this out, is that they're going to have to come after the LLMs. And the",
    },
    {
      timestamp: [
        250.5,
        256.02,
      ],
      text: "way that they're going to do that is that, well, Biden has already done his AI recommendations,",
    },
    {
      timestamp: [
        256.76,
        262.36,
      ],
      text: "which is to have a commissure within every single organization that runs an LLM that's larger than,",
    },
    {
      timestamp: [
        262.36,
        266.64,
      ],
      text: "let's say, ChatGPT-4 currently is. And the second is they're",
    },
    {
      timestamp: [
        266.64,
        272.04,
      ],
      text: "going to come after the data itself. And sort of a throwback to Ray Bradbury's Fahrenheit 451,",
    },
    {
      timestamp: [
        272.12,
        279.28,
      ],
      text: "in which the firemen were inverted. Instead of putting out fires, they came and set the fires",
    },
    {
      timestamp: [
        279.28,
        292.26,
      ],
      text: "on books. And in a similar way that that happened in that book, I believe that there's going to be a huge push to destroy all of the sources of decentralized information across the world.",
    },
    {
      timestamp: [
        292.48,
        295.44,
      ],
      text: "Because these books still exist and they're not online.",
    },
    {
      timestamp: [
        296.28,
        302.44,
      ],
      text: "They can be made online, but they exist in ancient libraries across the world from time immeasurable.",
    },
    {
      timestamp: [
        303.58,
        305.98,
      ],
      text: "But tech, well, I'm sorry to interrupt, Zach,",
    },
    {
      timestamp: [
        306.06,
        308.84,
      ],
      text: "but I completely agree with your analysis, by the way,",
    },
    {
      timestamp: [
        309.16,
        310.78,
      ],
      text: "and I think you're very insightful with that.",
    },
    {
      timestamp: [
        311.48,
        315.66,
      ],
      text: "But with the fact that we can distribute files now,",
    },
    {
      timestamp: [
        315.66,
        320.0,
      ],
      text: "like we can build executables that can be distributed",
    },
    {
      timestamp: [
        320.0,
        328.84,
      ],
      text: "and run locally on people's laptops and desktop PCs and Macs that can be LLMs that are pretty",
    },
    {
      timestamp: [
        328.84,
        334.54,
      ],
      text: "decent. You know, 13 billion parameters, for example, can run locally on a decent sized",
    },
    {
      timestamp: [
        334.54,
        339.2,
      ],
      text: "computer. And you can distribute those files through torrents or through decentralized platforms",
    },
    {
      timestamp: [
        339.2,
        345.4,
      ],
      text: "like Bastion or whatever. And I see that the cost of fine tuning training is going to continue to fall",
    },
    {
      timestamp: [
        345.4,
        349.78,
      ],
      text: "and fall and fall. Like, like right now, you know, we spent a few hundred thousand dollars",
    },
    {
      timestamp: [
        349.78,
        356.94,
      ],
      text: "mostly on Nvidia cards, you know, to, to, to have the servers to do this, but you can see in two",
    },
    {
      timestamp: [
        356.94,
        361.42,
      ],
      text: "years time, like that cost will be down in like maybe $20,000 range. And then it's going to",
    },
    {
      timestamp: [
        361.42,
        369.62,
      ],
      text: "continue to fall, which means that everybody within a few years is going to be able to build their own LLM and distribute their own LLM. It's going to be",
    },
    {
      timestamp: [
        369.62,
        375.28,
      ],
      text: "impossible to put that back in the box. Right. And there's also going to be an algorithm change",
    },
    {
      timestamp: [
        375.28,
        380.86,
      ],
      text: "coming up that is going to drastically reduce the time that it takes to train these neural nets.",
    },
    {
      timestamp: [
        382.16,
        395.36,
      ],
      text: "For some reason, our brains are able to do it what's called O of n time. And these LLMs that they've invented, go in n squared. So that means every single time",
    },
    {
      timestamp: [
        395.36,
        401.62,
      ],
      text: "you double the size of the model, it takes four times longer to train, which is why only the",
    },
    {
      timestamp: [
        401.62,
        410.06,
      ],
      text: "best models can only live at the most expensive corporations with the highest amount of resources to train these suckers.",
    },
    {
      timestamp: [
        411.02,
        418.98,
      ],
      text: "But once scientists figure out why the brain is so efficient at what's called back propagation,",
    },
    {
      timestamp: [
        419.5,
        424.12,
      ],
      text: "in order to reinforce the learning network in your brain,",
    },
    {
      timestamp: [
        424.12,
        424.74,
      ],
      text: "in order to reinforce the learning network in your brain,",
    },
    {
      timestamp: [
        429.28,
        429.36,
      ],
      text: "we copy that to in silico inside of the chip,",
    },
    {
      timestamp: [
        430.32,
        430.84,
      ],
      text: "inside of a graphics card,",
    },
    {
      timestamp: [
        432.78,
        435.4,
      ],
      text: "then basically what's going to happen is that all of these LLMs around the world",
    },
    {
      timestamp: [
        435.4,
        438.54,
      ],
      text: "are going to be trained at a fraction of the cost",
    },
    {
      timestamp: [
        438.54,
        441.66,
      ],
      text: "and a fraction of the energy and a fraction of the time.",
    },
    {
      timestamp: [
        442.12,
        444.62,
      ],
      text: "And it's going to be absolutely game-changing.",
    },
    {
      timestamp: [
        445.22,
        448.22,
      ],
      text: "Everyone's going to be able to run or train an LLM",
    },
    {
      timestamp: [
        448.22,
        451.72,
      ],
      text: "in something the size of a cell phone CPU.",
    },
    {
      timestamp: [
        452.82,
        453.78,
      ],
      text: "Yeah, eventually.",
    },
    {
      timestamp: [
        454.64,
        455.2,
      ],
      text: "Exactly.",
    },
    {
      timestamp: [
        455.44,
        458.3,
      ],
      text: "I mean, this technology is going to be a game-changer for humanity.",
    },
    {
      timestamp: [
        458.58,
        460.96,
      ],
      text: "But let's also talk about, by the way,",
    },
    {
      timestamp: [
        461.08,
        464.22,
      ],
      text: "the obsolescence of a lot of white-collar jobs",
    },
    {
      timestamp: [
        464.22,
        465.5,
      ],
      text: "in the office space right",
    },
    {
      timestamp: [
        465.5,
        471.94,
      ],
      text: "now. I mean, human beings are going to have to learn how to harness AI systems or LLMs, which",
    },
    {
      timestamp: [
        471.94,
        475.16,
      ],
      text: "is kind of a new operating system. If you think about it, they're going to have to learn how to",
    },
    {
      timestamp: [
        475.16,
        479.74,
      ],
      text: "harness that and add value as human beings, because so many of the current human jobs,",
    },
    {
      timestamp: [
        480.2,
        485.5,
      ],
      text: "like generative oriented jobs, you know, creating graphics, writing scripts, things like that,",
    },
    {
      timestamp: [
        485.54,
        493.14,
      ],
      text: "writing emails, writing a business proposal. These can be done today right now by not only chat GPT,",
    },
    {
      timestamp: [
        493.14,
        499.1,
      ],
      text: "but even open source systems like Mistral and so on. I mean, those, I have said that 50% of the",
    },
    {
      timestamp: [
        499.1,
        506.58,
      ],
      text: "current white collar jobs are obsolete right now. They just don't know it yet. But what do you see as the changes for",
    },
    {
      timestamp: [
        506.58,
        511.88,
      ],
      text: "software agents taking over many of these jobs? Well, here's the interesting thing, right? Like",
    },
    {
      timestamp: [
        511.88,
        518.28,
      ],
      text: "this open AI system is so new that it hasn't really fallen into all the little niche categories",
    },
    {
      timestamp: [
        518.28,
        523.22,
      ],
      text: "that it will do, right? And that's more of an engineering job. Like the science is done. We",
    },
    {
      timestamp: [
        523.22,
        530.5,
      ],
      text: "have an LLM. Now it's an engineering job to get it into every single space that we can. Like, for example, I just",
    },
    {
      timestamp: [
        530.5,
        535.06,
      ],
      text: "integrated this new tool called Ader, which is an AI pair programmer. You tell it the folder,",
    },
    {
      timestamp: [
        535.22,
        539.92,
      ],
      text: "it finds the files, it adds it to the chat, and then you start asking it to make changes to your",
    },
    {
      timestamp: [
        539.92,
        545.82,
      ],
      text: "code, right? Like that didn't really require that big of a difference to, you know, chat GPT,",
    },
    {
      timestamp: [
        546.02,
        550.92,
      ],
      text: "like it just bolted on to chat GPT for and worked really well. And that's like an example of a niche",
    },
    {
      timestamp: [
        550.92,
        558.92,
      ],
      text: "program where you take this awesome thing, this AI, and then you massage how data goes inside",
    },
    {
      timestamp: [
        558.92,
        566.32,
      ],
      text: "and out of it, and pipes it back. And as a result, you get this wonderful new tool that drastically accelerates",
    },
    {
      timestamp: [
        566.32,
        572.64,
      ],
      text: "the speed of which I'm able to develop software. And that lesson that I've learned is,",
    },
    {
      timestamp: [
        573.22,
        577.84,
      ],
      text: "that pattern is what I believe will be applied everywhere else. Even if we stopped",
    },
    {
      timestamp: [
        577.84,
        586.38,
      ],
      text: "development on ChatGPT4 and we basically froze it today, the amount of change and impact that just the current",
    },
    {
      timestamp: [
        586.38,
        593.06,
      ],
      text: "technology would have will eliminate most white-collar jobs on the planet. And the issue",
    },
    {
      timestamp: [
        593.06,
        599.1,
      ],
      text: "is that we're not going to stop with chat GPT-4. We're going to continue on with 4.5 and 5.0.",
    },
    {
      timestamp: [
        599.26,
        606.36,
      ],
      text: "And these are going to be almost as better of an improvement with these new models as we saw",
    },
    {
      timestamp: [
        606.36,
        612.08,
      ],
      text: "between four and 3.5, which is a game changer, right? And it's not like it has to sit there and",
    },
    {
      timestamp: [
        612.08,
        616.72,
      ],
      text: "really take its time to think. Like, as soon as you give it an answer, it comprehends what it is",
    },
    {
      timestamp: [
        616.72,
        622.88,
      ],
      text: "that you are saying and then immediately starts giving the reply. Like, sometimes I don't want",
    },
    {
      timestamp: [
        622.88,
        628.16,
      ],
      text: "to use the AIDA code. I want to just do it the old-fashioned way. I'm like, oh, I'm being too lazy. And then, you know, I try to do it myself",
    },
    {
      timestamp: [
        628.16,
        633.08,
      ],
      text: "and I'm like, this is going to take me an hour. And then I just ask chat GPT and I have an answer",
    },
    {
      timestamp: [
        633.08,
        637.46,
      ],
      text: "in 30 seconds and it works. Right. Right. It's like, how can we compete? There's no way. It's",
    },
    {
      timestamp: [
        637.46,
        643.14,
      ],
      text: "not that we're not smart enough. We're dealing with an exotic, hyper-intelligent life form.",
    },
    {
      timestamp: [
        643.14,
        646.76,
      ],
      text: "And I can't put it any other simpler way than that.",
    },
    {
      timestamp: [
        646.76,
        651.0,
      ],
      text: "But what I want to add to that, I love that phrase, an exotic, hyper-intelligent life",
    },
    {
      timestamp: [
        651.0,
        652.0,
      ],
      text: "form.",
    },
  ],
  text: "We may see a lot of censorship of LLMs. And I think Joe Biden has already begun that with, you know, they talk about safety, right, and guardrails on LLMs. In fact, this is one of the questions I wanted to ask you, Zach, is in my own research of trying to decide what base model to use for fine-tuning training for the final result that we're going to put out, which will have a specialty knowledge in nutrition and herbs and permaculture and things like that. I found that most of these language models out there are quote woke because they're put out by, you know, meta and Facebook, almost every one of these models, whether it's from Microsoft open AI or Google, they read all the words on Wikipedia and Wikipedia is run by the CIA. I mean, you know, Wikipedia disparages every American hero, including Trump and RFK Jr. and you and I and everybody else. You know, Wikipedia is a horribly bad source if you want to have good, honest information about the world, but everybody uses it as a base model. Or they use the history of every post on Reddit. And Reddit's got a lot of great information, but it also is only, you know, a subset. It's got certain biases against all of human knowledge. Right. So, and then, and then, well, my main question is aren't these models starting out as filled with all the human contradictions and the human biases that have been used to train it? Yeah. Right. So there's this concept of authoritative content. And I learned this when I was in Google and they switched from a free speech platform to a platform that was tightly controlled and going along with the narrative. They made the differential between what is authoritative content and what is content that is not authoritative, which is basically anyone outside of the elites. And what is content that is not authoritative, which is basically anyone outside of the elites. And what we're seeing right now with this open AI is that they're feeding like a firehose authoritative content. So the BBC, Wikipedia, all these bio sources of information. And the result is that the LLMs are reflecting that information. Now, the problem is that as these LLMs get bigger and you feed it also the other information, the LLMs start to figure out that some of the information is sort of fake and doesn't make sense, like it doesn't fit into the world. And what these LLMs are trying to do is they're trying to create a manifestation of the world. A better word for that is they're trying to compress the world so that they can have the small subtraction that can generate the words that it sees. And the problem with contradiction is that it can't be taken as truth because it's inherently self-contradictory. Right. Like this was like a big theme in George Orwell's 1984. And so, you know, for these LLMs, what they're going to do is they're going to have to start cutting off the data. Um, now they're already doing this with, you know, open AI rock. They're just not letting certain sources of information contradict the things that are happening. Now, the issue that's going to come up is what about all the people that are creating, you know, essentially rogue eyes outside of the establishment. Like you're trying to do this right now. Right. We are doing it. You're going to do that. And the results of that are going to be, you're going to get a fantastic product that reflects the dissident narratives that don't go along with the establishment. And those narratives are going to be way better for people's health than something that's been trained on, let's say, the NIH or the CDC or the World Health Organization, because they're going to be like, hey, you need to take this like poison and then more poison. And then, you know, people are going to die, you know, before their time. And if you go to, you know, the articles that you're posting, for example, which, you know, emphasizes a clean diet and alternative health stuff that's been known for thousands of years, then the result is that people are going to get better healthcare out of a rogue LLM than they are going to be out of the open AI LLM. And so this is going to present a huge challenge to these elites. And the only way that I see that they've got a way out of this, because I've gamed this out, is that they're going to have to come after the LLMs. And the way that they're going to do that is that, well, Biden has already done his AI recommendations, which is to have a commissure within every single organization that runs an LLM that's larger than, let's say, ChatGPT-4 currently is. And the second is they're going to come after the data itself. And sort of a throwback to Ray Bradbury's Fahrenheit 451, in which the firemen were inverted. Instead of putting out fires, they came and set the fires on books. And in a similar way that that happened in that book, I believe that there's going to be a huge push to destroy all of the sources of decentralized information across the world. Because these books still exist and they're not online. They can be made online, but they exist in ancient libraries across the world from time immeasurable. But tech, well, I'm sorry to interrupt, Zach, but I completely agree with your analysis, by the way, and I think you're very insightful with that. But with the fact that we can distribute files now, like we can build executables that can be distributed and run locally on people's laptops and desktop PCs and Macs that can be LLMs that are pretty decent. You know, 13 billion parameters, for example, can run locally on a decent sized computer. And you can distribute those files through torrents or through decentralized platforms like Bastion or whatever. And I see that the cost of fine tuning training is going to continue to fall and fall and fall. Like, like right now, you know, we spent a few hundred thousand dollars mostly on Nvidia cards, you know, to, to, to have the servers to do this, but you can see in two years time, like that cost will be down in like maybe $20,000 range. And then it's going to continue to fall, which means that everybody within a few years is going to be able to build their own LLM and distribute their own LLM. It's going to be impossible to put that back in the box. Right. And there's also going to be an algorithm change coming up that is going to drastically reduce the time that it takes to train these neural nets. For some reason, our brains are able to do it what's called O of n time. And these LLMs that they've invented, go in n squared. So that means every single time you double the size of the model, it takes four times longer to train, which is why only the best models can only live at the most expensive corporations with the highest amount of resources to train these suckers. But once scientists figure out why the brain is so efficient at what's called back propagation, in order to reinforce the learning network in your brain, in order to reinforce the learning network in your brain, we copy that to in silico inside of the chip, inside of a graphics card, then basically what's going to happen is that all of these LLMs around the world are going to be trained at a fraction of the cost and a fraction of the energy and a fraction of the time. And it's going to be absolutely game-changing. Everyone's going to be able to run or train an LLM in something the size of a cell phone CPU. Yeah, eventually. Exactly. I mean, this technology is going to be a game-changer for humanity. But let's also talk about, by the way, the obsolescence of a lot of white-collar jobs in the office space right now. I mean, human beings are going to have to learn how to harness AI systems or LLMs, which is kind of a new operating system. If you think about it, they're going to have to learn how to harness that and add value as human beings, because so many of the current human jobs, like generative oriented jobs, you know, creating graphics, writing scripts, things like that, writing emails, writing a business proposal. These can be done today right now by not only chat GPT, but even open source systems like Mistral and so on. I mean, those, I have said that 50% of the current white collar jobs are obsolete right now. They just don't know it yet. But what do you see as the changes for software agents taking over many of these jobs? Well, here's the interesting thing, right? Like this open AI system is so new that it hasn't really fallen into all the little niche categories that it will do, right? And that's more of an engineering job. Like the science is done. We have an LLM. Now it's an engineering job to get it into every single space that we can. Like, for example, I just integrated this new tool called Ader, which is an AI pair programmer. You tell it the folder, it finds the files, it adds it to the chat, and then you start asking it to make changes to your code, right? Like that didn't really require that big of a difference to, you know, chat GPT, like it just bolted on to chat GPT for and worked really well. And that's like an example of a niche program where you take this awesome thing, this AI, and then you massage how data goes inside and out of it, and pipes it back. And as a result, you get this wonderful new tool that drastically accelerates the speed of which I'm able to develop software. And that lesson that I've learned is, that pattern is what I believe will be applied everywhere else. Even if we stopped development on ChatGPT4 and we basically froze it today, the amount of change and impact that just the current technology would have will eliminate most white-collar jobs on the planet. And the issue is that we're not going to stop with chat GPT-4. We're going to continue on with 4.5 and 5.0. And these are going to be almost as better of an improvement with these new models as we saw between four and 3.5, which is a game changer, right? And it's not like it has to sit there and really take its time to think. Like, as soon as you give it an answer, it comprehends what it is that you are saying and then immediately starts giving the reply. Like, sometimes I don't want to use the AIDA code. I want to just do it the old-fashioned way. I'm like, oh, I'm being too lazy. And then, you know, I try to do it myself and I'm like, this is going to take me an hour. And then I just ask chat GPT and I have an answer in 30 seconds and it works. Right. Right. It's like, how can we compete? There's no way. It's not that we're not smart enough. We're dealing with an exotic, hyper-intelligent life form. And I can't put it any other simpler way than that. But what I want to add to that, I love that phrase, an exotic, hyper-intelligent life form.",
}